{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction based on Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "from pricing_data import krx_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Description\n",
    "- index = 'date', 'ticker'\n",
    "- Target: 'target'\n",
    "- Variables:\n",
    "  - Market return based: 'market_return', 'excess_market_return'\n",
    "  - Fama French 3 factor: 'ff3_bin_return', 'smb', 'hml', \n",
    "  - CAPM: 'const', 'beta', 'ido_vol', 'beta_seq', \n",
    "  - Fundamental: 'EPR', 'BPR', 'div_ret','div'\n",
    "  - ETC:\n",
    "    - 'size_rnk', 'share_turnover', 'share_turnover_rnk', 'std12', 'cross_rnk', 'time_rnk',\n",
    "    - Momentum:'mom1', 'mom2', 'mom3', 'mom4', 'mom5', 'mom6', 'mom7', 'mom8', 'mom9', 'mom10', 'mom11', 'mom12', \n",
    "    - Support line(based on price): 'support_low', 'support_high'\n",
    "  - Macro\n",
    "    - Korean Treasury: 'tb3y', 'tb5y', 'tb10y', 'cb3y'\n",
    "    - usd/krw: 'change_usd_krw_monthly', 'lo_usd_krw_monthly', 'ho_usd_krw_monthly', 'co_usd_krw_monthly', 'change_usd_krw_daily', 'lo_usd_krw_daily', 'ho_usd_krw_daily', 'co_usd_krw_daily',\n",
    "    - WTI: 'change_wti', 'lo_wti', 'ho_wti', 'co_wti', \n",
    "    - Market Portfolio: 'change_nasdaq', 'lo_nasdaq', 'ho_nasdaq', 'co_nasdaq', 'close_sp500', 'change_sp500', 'lo_sp500', 'ho_sp500', 'co_sp500',\n",
    "    - US Treasury: 'close_bond_10y', 'close_bond_2y', 'close_bond_1m', 'close_bond_1y', \n",
    "    - VIX:'close_vix', 'change_vix', 'lo_vix', 'ho_vix', 'co_vix',\n",
    "  - Log:'log_mom1', 'log_mom2', 'log_mom3', 'log_mom4', 'log_EPR', 'log_share_turnover', 'log_mom6', 'log_mom5', 'log_mom12', 'log_mom11', 'log_mom10', 'log_mom8', 'log_mom9', 'log_mom7', 'log_std12', 'log_BPR', 'log_change_wti', 'log_ff3_bin_return', 'log_ho_wti', 'log_ho_usd_krw_monthly', 'log_smb', 'log_co_sp500', 'log_change_usd_krw_daily', 'log_ho_vix', 'log_change_vix', 'log_change_usd_krw_monthly', 'log_ho_usd_krw_daily', 'log_ho_sp500', 'log_close_vix', 'log_ho_nasdaq', 'log_co_usd_krw_daily', 'log_close_bond_1m', 'log_change_sp500', 'log_co_nasdaq', 'log_close_bond_1y', 'log_close_bond_2y', 'log_ido_vol', 'log_change_nasdaq', 'log_close_sp500', 'log_lo_usd_krw_daily', 'log_lo_nasdaq', 'log_lo_sp500', 'log_lo_usd_krw_monthly', 'log_beta_seq', 'log_beta', 'log_hml', 'log_co_usd_krw_monthly', 'log_lo_wti', \n",
    "  - Categorical: 'vix_cat_mid', 'vix_cat_high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data Split: 100%|██████████| 15/15 [00:00<00:00, 18.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109799, 118)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Int64Index([2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017,\n",
       "            2018, 2019, 2020, 2021],\n",
       "           dtype='int64', name='date')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test, test_years = krx_data()\n",
    "\n",
    "print(train[test_years[-1]][1].shape)\n",
    "test_years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from MLutils.SklearnUtils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Out\\ of\\ Sample\\ R^2$ by Campbel and Thomson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_os(y_real, y_pred): # \n",
    "    return 1 - ((y_real-y_pred)**2).sum() /((y_real- y_real.mean())**2).sum()\n",
    "\n",
    "    # mse_m = ((y_pred.reshape(-1) - y_real)**2).mean()\n",
    "    # mse_bm = (y_real**2).mean()\n",
    "    # return 1 - mse_m / mse_bm\n",
    "\n",
    "r2os = make_scorer(r_os, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = 77  # random_state\n",
    "\n",
    "\n",
    "class Regressions:\n",
    "    def __init__(self, year, x, y, x_test, y_test):\n",
    "        self.y = y.values\n",
    "        self.x = x.values\n",
    "        self.y_test = y_test.values.reshape(-1, 1)\n",
    "        self.x_test = x_test.values\n",
    "        self.year = year\n",
    "\n",
    "        self.models = ['lin', 'en', 'pls', 'pcr', 'rf', 'gbr']\n",
    "        self.res_cols = ['year', 'name', 'params', 'pred_R2_OOS', 'train_score',\n",
    "                         'CV_R2', 'CV_MSE', 'complexity']\n",
    "\n",
    "        self.error = []\n",
    "        self.res = []\n",
    "        self.result = pd.DataFrame()\n",
    "        \n",
    "    def reset(self, year, x, y, x_test, y_test):\n",
    "        self.y = y.values\n",
    "        self.x = x.values\n",
    "        self.y_test = y_test.values.reshape(-1, 1)\n",
    "        self.x_test = x_test.values\n",
    "        self.year = year\n",
    "        \n",
    "        self.error = []\n",
    "        self.res = []\n",
    "\n",
    "    def execute(self, model, params, name):\n",
    "        reg, _ = learning(self.x, self.y, regressor=model, params=params, pred=False, scores=[\n",
    "                          'r2', 'neg_mean_squared_error'], refit='r2', verbose = 0)\n",
    "\n",
    "        if name == 'en':\n",
    "            complexity = (reg.best_estimator_.coef_ != 0).sum()\n",
    "        elif name == 'rf':\n",
    "            complexity = np.mean(\n",
    "                [estimator.tree_.max_depth for estimator in reg.best_estimator_.estimators_])\n",
    "        elif name == 'gbr':\n",
    "            complexity = np.mean(\n",
    "                [estimator.max_features_ for estimator in reg.best_estimator_.estimators_.reshape(-1)])\n",
    "        elif name == 'pls':\n",
    "            complexity = reg.best_params_\n",
    "        elif name == 'pcr':\n",
    "            complexity = reg.best_params_['pca__n_components']\n",
    "\n",
    "        pred_score = r2os(reg, self.x_test, self.y_test)\n",
    "\n",
    "        # year, name, best CV result, prediction score (R^2 OOS),\n",
    "        #   training set score(R^2), CV result(R^2), CV result(MSE), complexity\n",
    "        self.res.append([self.year, name, reg.best_params_, pred_score,\n",
    "                        reg.score(self.x, self.y), reg.best_score_, -reg.cv_results_['mean_test_neg_mean_squared_error'], complexity])\n",
    "\n",
    "        return reg\n",
    "\n",
    "    @property\n",
    "    def lin(self):\n",
    "        model = LinearRegression(fit_intercept=True)\n",
    "        model.fit(self.x, self.y)\n",
    "        score = model.score(self.x, self.y)\n",
    "        mse = mean_squared_error(self.y, model.predict(self.x))\n",
    "        pred_score = r2os(model, self.x_test, self.y_test)\n",
    "        self.res.append(\n",
    "            [self.year, 'lin', 0, pred_score, r2_score(self.y, model.predict(self.x)),\n",
    "             score, mse, 0])\n",
    "\n",
    "    @property\n",
    "    def en(self):\n",
    "        model = ElasticNet(max_iter=10000, random_state=rnd)\n",
    "        params = {'alpha': np.linspace(\n",
    "            20, 150, 10), 'l1_ratio': np.linspace(0.1, 1, 10)}\n",
    "        reg = self.execute(model, params, 'en')\n",
    "        return reg\n",
    "\n",
    "    @property\n",
    "    def pcr(self):\n",
    "        model = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('pca', PCA()),\n",
    "            ('linear', LinearRegression(fit_intercept=True))])\n",
    "        params = {'pca__n_components': np.arange(1, 10)}  # self.x.shape[1]+1)}\n",
    "        reg = self.execute(model, params, 'pcr')\n",
    "        return reg\n",
    "\n",
    "    @property\n",
    "    def pls(self):\n",
    "        model = PLSRegression(random_state=rnd)\n",
    "        params = {'n_components': np.arange(1, self.x.shape[1]+1)}\n",
    "        reg = self.execute(model, params, 'pls')\n",
    "        return reg\n",
    "\n",
    "    @property\n",
    "    def rf(self):\n",
    "        dt = RandomForestRegressor(random_state=rnd).fit(x, y)\n",
    "        model = RandomForestRegressor(random_state=rnd)\n",
    "        params = {\n",
    "            'n_estimators': [10, 20, 50,],\n",
    "            'max_depth': np.arange(1, dt.tree_.max_depth+1, int(dt.tree_.max_depth/5)),\n",
    "        }\n",
    "        reg = self.execute(model, params, 'rf')\n",
    "        return reg\n",
    "\n",
    "    @property\n",
    "    def gbr(self):\n",
    "        model = GradientBoostingRegressor(random_state=rnd)\n",
    "        params = {\n",
    "            'learning_rate': np.linspace(0.01, 0.1, 3),\n",
    "            'max_depth': [3,7,10,20, 50],\n",
    "            # 'max_features': range(1, len(dt1.feature_importances_)+1)\n",
    "        }\n",
    "        reg = self.execute(model, params, 'gbr')\n",
    "        return reg\n",
    "\n",
    "    def fit_all(self):\n",
    "        try:\n",
    "            # for i in self.models:\n",
    "            #     getattr(self, i)\n",
    "            i = 'lin'\n",
    "            getattr(self, i)\n",
    "        except:\n",
    "            print(f'Error while model {i} in {self.year}')\n",
    "            self.error.append((self.year, i))\n",
    "\n",
    "        if len(self.error) != 0:\n",
    "            with open('error.csv', 'a') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerows(self.error)\n",
    "\n",
    "        result = pd.DataFrame(self.res, columns=self.res_cols)\n",
    "        if len(self.result) != 0:\n",
    "            result.to_csv('result.csv', mode='a', header=False, index=False)\n",
    "        else:\n",
    "            result.to_csv('result.csv', index=False)\n",
    "\n",
    "        self.result = pd.concat([self.result, result], axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2021: 100%|██████████| 15/15 [00:27<00:00,  1.82s/it]\n"
     ]
    }
   ],
   "source": [
    "start = True\n",
    "pbar = tqdm(test_years)\n",
    "for year in pbar:\n",
    "    pbar.set_description(f\"Processing {year}\")\n",
    "    y, x = train[year]\n",
    "    y_test, x_test = test[year]\n",
    "    if start == True:\n",
    "        mod = Regressions(year, x, y, x_test, y_test)\n",
    "        start = False\n",
    "    else:\n",
    "        mod.reset(year, x, y, x_test, y_test)\n",
    "    \n",
    "    mod.fit_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>params</th>\n",
       "      <th>pred_R2_OOS</th>\n",
       "      <th>train_score</th>\n",
       "      <th>CV_R2</th>\n",
       "      <th>CV_MSE</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007</td>\n",
       "      <td>lin</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.910209e+07</td>\n",
       "      <td>0.252776</td>\n",
       "      <td>0.252776</td>\n",
       "      <td>3.190037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>lin</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.885779e+09</td>\n",
       "      <td>0.239861</td>\n",
       "      <td>0.239861</td>\n",
       "      <td>2.973091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>lin</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.360745e+08</td>\n",
       "      <td>0.241650</td>\n",
       "      <td>0.241650</td>\n",
       "      <td>2.826106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>lin</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.193419e+08</td>\n",
       "      <td>0.428791</td>\n",
       "      <td>0.428791</td>\n",
       "      <td>2.048899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>lin</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.792582e+06</td>\n",
       "      <td>0.017706</td>\n",
       "      <td>0.017706</td>\n",
       "      <td>0.665855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>lin</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.255555e+06</td>\n",
       "      <td>0.019353</td>\n",
       "      <td>0.019353</td>\n",
       "      <td>0.542659</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>lin</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.772988e+07</td>\n",
       "      <td>0.026582</td>\n",
       "      <td>0.026582</td>\n",
       "      <td>0.301652</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>lin</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.085100e+06</td>\n",
       "      <td>0.026734</td>\n",
       "      <td>0.026734</td>\n",
       "      <td>0.239406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>lin</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.991220e+05</td>\n",
       "      <td>0.020513</td>\n",
       "      <td>0.020513</td>\n",
       "      <td>0.191733</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>lin</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.605314e+05</td>\n",
       "      <td>0.045877</td>\n",
       "      <td>0.045877</td>\n",
       "      <td>0.137392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>lin</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.016795e+08</td>\n",
       "      <td>0.041863</td>\n",
       "      <td>0.041863</td>\n",
       "      <td>0.128581</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>lin</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.060873e+06</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.093242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>lin</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.255830e+05</td>\n",
       "      <td>0.037254</td>\n",
       "      <td>0.037254</td>\n",
       "      <td>0.087867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>lin</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.707260e+14</td>\n",
       "      <td>0.035920</td>\n",
       "      <td>0.035920</td>\n",
       "      <td>0.086238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>lin</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.354073e+17</td>\n",
       "      <td>0.058489</td>\n",
       "      <td>0.058489</td>\n",
       "      <td>0.067935</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year name  params   pred_R2_OOS  train_score     CV_R2    CV_MSE  \\\n",
       "0  2007  lin       0 -2.910209e+07     0.252776  0.252776  3.190037   \n",
       "0  2008  lin       0 -8.885779e+09     0.239861  0.239861  2.973091   \n",
       "0  2009  lin       0 -8.360745e+08     0.241650  0.241650  2.826106   \n",
       "0  2010  lin       0 -3.193419e+08     0.428791  0.428791  2.048899   \n",
       "0  2011  lin       0 -1.792582e+06     0.017706  0.017706  0.665855   \n",
       "0  2012  lin       0 -2.255555e+06     0.019353  0.019353  0.542659   \n",
       "0  2013  lin       0 -8.772988e+07     0.026582  0.026582  0.301652   \n",
       "0  2014  lin       0 -2.085100e+06     0.026734  0.026734  0.239406   \n",
       "0  2015  lin       0 -6.991220e+05     0.020513  0.020513  0.191733   \n",
       "0  2016  lin       0 -7.605314e+05     0.045877  0.045877  0.137392   \n",
       "0  2017  lin       0 -4.016795e+08     0.041863  0.041863  0.128581   \n",
       "0  2018  lin       0 -7.060873e+06     0.027200  0.027200  0.093242   \n",
       "0  2019  lin       0 -2.255830e+05     0.037254  0.037254  0.087867   \n",
       "0  2020  lin       0 -1.707260e+14     0.035920  0.035920  0.086238   \n",
       "0  2021  lin       0 -1.354073e+17     0.058489  0.058489  0.067935   \n",
       "\n",
       "   complexity  \n",
       "0           0  \n",
       "0           0  \n",
       "0           0  \n",
       "0           0  \n",
       "0           0  \n",
       "0           0  \n",
       "0           0  \n",
       "0           0  \n",
       "0           0  \n",
       "0           0  \n",
       "0           0  \n",
       "0           0  \n",
       "0           0  \n",
       "0           0  \n",
       "0           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1t/_7p_zm4x449blqs7bvqvb0rm0000gn/T/ipykernel_64366/2385352082.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/hun/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hun/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m    664\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hun/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hun/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \"\"\"\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1316\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hun/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " reg = GradientBoostingRegressor(random_state=rnd, max_depth = 50, n_estimators=100).fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.303447192240039"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  3.,  4.,  7., 10.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.geomspace(2, 10, 5))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d65ee25941e053fc158c8cdbf16a2c8e0c30dd307bb49595affda86b2eeb7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('hun')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
